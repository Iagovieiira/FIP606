[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Aula1.html",
    "href": "Aula1.html",
    "title": "Aprendendo funções básicas no R.",
    "section": "",
    "text": "Para dar início nesta  primeira aula será feita uma breve introdução aos softwares R e RStudio, apresentando como criar projetos, instalar e carregar pacotes e criar vetores, data frames e realizar operações básicas no RStudio."
  },
  {
    "objectID": "Aula1.html#para-criar-um-projeto",
    "href": "Aula1.html#para-criar-um-projeto",
    "title": "Aprendendo funções básicas no R.",
    "section": "Para criar um projeto",
    "text": "Para criar um projeto\nInicialmente, será criado um projeto, onde serão mantidos todos os arquivos da disciplina. Para isso, bastar clicar em:\n\n“File” -&gt; “New Project…” -&gt; “New Directory” -&gt; “New Project”\nDa-se um nome ao projeto e escolhida a pasta em que ele será mantido. Feito isso, prosseguimos, clicando em “Create Project”.\nInstalando e carregando pacotes\nOs pacotes são fundamentais para o funcionamento do RStudio, pois contém funções que serão utilizadas em várias análises no decorrer da disciplina. Um pacote pode ser instalado manualmente, seguindo os passos:\n“Packages” -&gt; “Install” -&gt; Na linha “Packages”, digite o nome do pacote de interesse, no qual foi usado o exemplo do “Agricolae”. -&gt; Em seguida, clique em “Install”"
  },
  {
    "objectID": "Aula1.html#para-criar-vetores",
    "href": "Aula1.html#para-criar-vetores",
    "title": "Aprendendo funções básicas no R.",
    "section": "Para criar vetores",
    "text": "Para criar vetores\nValores adiconados aqui, irão aparecer como objetos com dados #uso de dois ** para deixar em negrito exemplo #uso de um * deixa ele em itálico exemplo.\n\n#usando a programação para a criação de vetores \n\nx &lt;- 10\ny &lt;- x * 10 \nz &lt;- x * y\n\n#Também é possível criar um vetor com um conjunto de valores:\n\nA &lt;- c(1:10)\n\nb &lt;- c(11:20)"
  },
  {
    "objectID": "Aula1.html#para-criar-data-frames",
    "href": "Aula1.html#para-criar-data-frames",
    "title": "Aprendendo funções básicas no R.",
    "section": "Para criar data frames",
    "text": "Para criar data frames\nPara criação de dataframes, é utilizada a função data.frame. Primeiros é dado um nome ao objeto (df), em seguida especificamos o que será colocado nele (os vetores A e B).\n\ndf &lt;- data.frame(A,b)\n\ndates&lt;-c(14,21,28) \n# days\n# example 1: evaluation - vector\nevaluation&lt;-c(40,80,90)\naudpc(evaluation,dates)\n\nevaluation \n      1015 \n\n#visualiza\nplot(pressure)\n\n\n\nstr(pressure)\n\n'data.frame':   19 obs. of  2 variables:\n $ temperature: num  0 20 40 60 80 100 120 140 160 180 ...\n $ pressure   : num  0.0002 0.0012 0.006 0.03 0.09 0.27 0.75 1.85 4.2 8.8 ...\n\ndf &lt;- cars\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\n#df$dist é uma forma de acessar uma coluna específica chamada \"dist\" de um data frame chamado df. \n\ndf$dist &lt;- log(df$dist)\nplot(df$dist)\n\n\n\ndf$dist\n\n [1] 0.6931472 2.3025851 1.3862944 3.0910425 2.7725887 2.3025851 2.8903718\n [8] 3.2580965 3.5263605 2.8332133 3.3322045 2.6390573 2.9957323 3.1780538\n[15] 3.3322045 3.2580965 3.5263605 3.5263605 3.8286414 3.2580965 3.5835189\n[22] 4.0943446 4.3820266 2.9957323 3.2580965 3.9889840 3.4657359 3.6888795\n[29] 3.4657359 3.6888795 3.9120230 3.7376696 4.0253517 4.3307333 4.4308168\n[36] 3.5835189 3.8286414 4.2195077 3.4657359 3.8712010 3.9512437 4.0253517\n[43] 4.1588831 4.1896547 3.9889840 4.2484952 4.5217886 4.5325995 4.7874917\n[50] 4.4426513"
  },
  {
    "objectID": "Aula1.html#para-pedir-ajuda",
    "href": "Aula1.html#para-pedir-ajuda",
    "title": "Aprendendo funções básicas no R.",
    "section": "Para pedir ajuda",
    "text": "Para pedir ajuda\nUtiliza o “help”. Aparece a resposta do que a função faz na aba de ajuda “help”, Além da opção apresentada no chunck pode pedir ajuda da seguinte forma: ?função.\n\nhelp(data.frame)"
  },
  {
    "objectID": "Aula11.html",
    "href": "Aula11.html",
    "title": "Aula 11",
    "section": "",
    "text": "Aula 11 - 19/06/2024\nCriando mapas no R\nPacotes\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(remotes)\nlibrary(rnaturalearth)\nlibrary(r4pde)\nlibrary(ggthemes)\nlibrary(ggspatial)\nlibrary(plotly)\nlibrary(leaflet)\nlibrary(ggrepel)\nlibrary(scatterpie)\n\nIstalando pacotes do repositorio github:\n\nremotes::install_github(\"ropensci/rnaturalearthhires\")\n\n\nBRA &lt;- ne_states (country = \"Brazil\",\n                  returnclass = \"sf\")\n\nworld &lt;- ne_countries()\n\nsbr &lt;- RustSoybean\n\nggplot(BRA) + geom_sf(fill = \"white\", color = \"blue\", linewidth = 1) +\n  geom_point(data = sbr, aes(longitude, latitude), color =\"black\") + theme_map()\n\n\n\n\n\nsbr &lt;- RustSoybean\n\nsbr |&gt; \n  ggplot(aes(longitude, latitude)) +\n  geom_point()+coord_sf()\n\n\n\n\n\nBRA &lt;- ne_states (country = \"Brazil\",\n                  returnclass = \"sf\")\nMG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\nbra &lt;- ggplot(BRA) +\n  geom_sf(fill = \"white\", color = \"blue\", linewidth = 0.5) +\n  geom_point(data = MG, aes(longitude, latitude), color =\"red\") + theme_map() +\n  annotation_north_arrow(which_north = \"grid\")\n\nPara criar um objeto BRA no ggplot\n\nlibrary(plotly)\nggplotly(bra)\n\n\n\n\n\nPara criar um mapa realista:\n\nvicosa &lt;- leaflet() |&gt; \n  addTiles() |&gt; \n  addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt;\n  setView(lng = -42.8825, lat = -20.7546, zoom = 5)\nvicosa\n\n\n\n\n\n\nvicosa &lt;- leaflet(sbr) |&gt; \n  addTiles() |&gt; \n  #addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt;\n  #setView(lng = -42.8825, lat = -20.7546, zoom = 5) |&gt; \n  addCircleMarkers(radius = 2)\nvicosa\n\n\n\n\n\n\nViçosa &lt;- leaflet() |&gt; \n  addTiles() |&gt; \n  setView(lng = -42.8825, lat = - 20.7546, zoom = 15)\nViçosa\n\n\n\n\n\nPara usar um grafico de pizza, muito usado para demosntrar genotipos.\n\nmapa &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1pAIFKsdKxk_UQQXdYwIO-O5NOkYNhpclImJcLziYnk4/edit?usp=sharing\")\n\nggplot(BRA) +\n  geom_sf(fill = \"gray70\", alpha = 0.5, color = \"white\") +\n  coord_sf()+\n  geom_scatterpie(aes(x = lon, y = lat, r = 0.6), alpha = 0.8, color = NA, data = mapa,\n                  cols = c(\"DFC\",\n                           \"MA\",\n                           \"FER\",\n                           \"ANTR\",\n                           \"OIDIO\"))+\n  geom_text_repel(data = mapa, aes(lon, lat, label = Local),\n                   size = 2, nudge_x = 0.2, nudge_y = 0.27, color = \"gray30\", family = \"Arial\") +\n  ggthemes::scale_fill_calc()+\n  ggthemes::theme_map() +\n  labs(x = \"Longitude\", y = \"Latitude\", legend = \"\", fill = \"Doença\")+\n  theme(legend.position = \"bottom\", text = element_text(family = \"Arial\", size = 8))"
  },
  {
    "objectID": "Aula2.html",
    "href": "Aula2.html",
    "title": "Importação de dados e criação de gráficos simples",
    "section": "",
    "text": "Nesta aula 2, serão apresentadas formas de se importar (carregar) dados/ planilhas, a partir de diferentes fontes, e como fazer uma análise visual rápida dos dados obtidos. Para utilizar os dados desse pacote é necessário conhecer a função e o que se quer especificar dentro desse pacote. Abaixo seguem alguns meios de importação de dados."
  },
  {
    "objectID": "Aula2.html#importando-dados-planilhas",
    "href": "Aula2.html#importando-dados-planilhas",
    "title": "Importação de dados e criação de gráficos simples",
    "section": "Importando dados/ planilhas",
    "text": "Importando dados/ planilhas\n\n# IMPORTAÇÕES: \nlibrary(ec50estimator)\ndf1 &lt;- multi_isolate\n\n#DO EXEL \n\nlibrary(readxl)\ndf2 &lt;- read_excel (\"dados-diversos.xlsx\")\n\n#aba \n\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", \"escala\")\n\n# DE ARQUIVOS CSV \n\nlibrary(tidyverse)\ndf3 &lt;- read_csv(\"dados-diversos.csv\")\n\n#planilha GOOGLE - IMPORTAR \n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")"
  },
  {
    "objectID": "Aula2.html#uso-do-tidyverse-ggplot2-para-visualização-rápida-dos-dados",
    "href": "Aula2.html#uso-do-tidyverse-ggplot2-para-visualização-rápida-dos-dados",
    "title": "Importação de dados e criação de gráficos simples",
    "section": "Uso do tidyverse (ggplot2) para visualização rápida dos dados",
    "text": "Uso do tidyverse (ggplot2) para visualização rápida dos dados\nPara visualizar os dados, é necessário carregar o pacote responsável pela criação dos gráficos. A variável resposta que se deseja observar deve estar no eixo y. Ao abrir a função do ggplot abaixo do pipe, é preciso escolher o que ficará no eixo x e no y.\nO ggplot trabalha em camadas, então, na primeira camada, você define os aspectos estéticos (aesthetic), adicionando camadas conforme deseja adicionar ou editar elementos no gráfico. Dentro do geom_jitter, você insere os pontos de dispersão e pode ajustar a distância entre eles, “organizando-os” no gráfico com o comando \"width\".\nQuanto mais simétrico estiver o box, mais normal será a distribuição dos dados. Para definir a escala do gráfico, você utiliza a função scale_y_continuous, especificando o limite do intervalo com (limits = c(0, 20)). O número de divisões da escala do gráfico é ajustado com a função n.breaks (= 10).\n\nlibrary(ggplot2)\n  g1&lt;- df4 |&gt; \n  ggplot(aes(trat, comp)) +\n    geom_boxplot(outlier.colour = NA)+\n    geom_jitter(width = 0.05,\n                color =\"black\",\n                shape =2,\n                size =3)+\n    theme_classic() +\n    labs(x = \"tratamento\",\n         y = \"Comprimento (mm)\",\n         title = \"meu primeiro ggplot\", \n         caption = \"fonte: dados diversos\")\n  scale_y_continuous(limits = c (0,20),\n                     n.breaks = 10)\n\n&lt;ScaleContinuousPosition&gt;\n Range:  \n Limits:    0 --   20\n\n  g1\n\n\n\n # ggsave(\"plot1.png\", bg = \"white\")"
  },
  {
    "objectID": "Aula3.html",
    "href": "Aula3.html",
    "title": "Importação, visualização e criação de subconjuntos",
    "section": "",
    "text": "Durante a aula 3, serão apresentadas ferramentas para se realizar uma análise descritiva do conjunto de dados. Além disso, o pacote tidyverse será utilizado para manipulação, criação de subconjuntos e organização dos dados."
  },
  {
    "objectID": "Aula3.html#importando-dados",
    "href": "Aula3.html#importando-dados",
    "title": "Importação, visualização e criação de subconjuntos",
    "section": "Importando dados",
    "text": "Importando dados\nPara importação de um conjunto de dados .csv na web.os dados utlizados serão importados de um arquivo .csv disponível em nuvem. Entretanto, o arquivo traz valores de incidência e severidade da ferrugem do cafeeiro em diferentes regiões da Etiópia, de acordo com o sistema de cultivo, manejo da fazenda, sombreamento, cultivar…\n\nlibrary(tidyverse)\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n  \n# Mostrar as variaveis dos dados importados \nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…\n\n# Distribuição da doença (severidade: quanto de doença tenho em cada folha) e incidencia: Proporção de ausencia e presença da doença seja em folhas ou em plantas\n\n\n\n## como esta destribuida a incidencia da doença nas fazendas (criar um histograma)\n\ncr |&gt; \n  \n  ggplot(aes(x = inc))+\n  geom_histogram()\n\n\n\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\n# Neste caso é multimodal (vairios picos nesse caso antes de 50%)\n#No histograma gerado, é possível notar que os valores de incidência apresentam três picos (ou seja, são valores de incidência com maior frequência). Além disso, a incidência aparenta não seguir distribuição normal, uma vez que o histograma apresenta um deslocamento à esquerda."
  },
  {
    "objectID": "Aula3.html#sumarização-dos-dados",
    "href": "Aula3.html#sumarização-dos-dados",
    "title": "Importação, visualização e criação de subconjuntos",
    "section": "Sumarização dos dados",
    "text": "Sumarização dos dados\nusando as funções “group_bay” e “summary”:\n\n summary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\n #mediana é o valor central"
  },
  {
    "objectID": "Aula3.html#sumarização-dos-dados-1",
    "href": "Aula3.html#sumarização-dos-dados-1",
    "title": "Importação, visualização e criação de subconjuntos",
    "section": "Sumarização dos dados",
    "text": "Sumarização dos dados\n\nÉ possível criar histogramas por algum critério, por exemplo, as regiões. Para isso, será utilizada a função facet_wrap e a função summarize que serve para resumir ou agregar dados, calculando estatísticas como médias, medianas, desvios padrão, contagens, entre outros, com base em grupos definidos.\n\n\n#Agrupamento por região\ncr |&gt; \n  ggplot(aes(x = inc))+\n  geom_boxplot()+\n  facet_wrap(~region)\n\n\n\n\n\n#MÉDIA: A média é uma medida de tendência central que representa o valor típico de um conjunto de dados. \n\ncr |&gt; \ngroup_by(region) |&gt; \n  summarize(inc_mean = mean(inc))\n\n# A tibble: 2 × 2\n  region inc_mean\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Oromia     37.0\n2 SNNPR      33.4\n\n\n\n#Média, mediana, cultivar da região \ncr |&gt; \ngroup_by(region) |&gt; \n  summarise(inc_med= median (inc), inc_mean = mean(inc), sd_mean = sd(inc)) \n\n# A tibble: 2 × 4\n  region inc_med inc_mean sd_mean\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Oromia    39.5     37.0    14.6\n2 SNNPR     29.6     33.4    18.9\n\n\n\ncr |&gt; \n  ggplot(aes (inc, sev2))+\n  geom_point()\n\n\n\n#No gráfico gerado é possível observar que há alta correlação positiva entre as variáveis severidade e incidência.\n\n\ncr |&gt; \n  ggplot(aes(x = inc))+\n  geom_histogram()+\n  facet_wrap(~region)\n\n\n\n# neste caso a mediana e média são mais distantes \n\n\ncr |&gt; \n  summarise(sev_med= median (sev2),\n            sev_mean = mean(sev2),\n            sd_mean = sd(sev2)) \n\n# A tibble: 1 × 3\n  sev_med sev_mean sd_mean\n    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1    5.95     9.09    9.22\n\n# o que prova que a mediana e a média são mais distates \n\n\nAnálise da severidade\n\nSerão realizadas análises de severidade em função da região e da cultivar. Será utilizada a função group_by.\n\n\n# por cultivar \ncr |&gt; \ngroup_by(cultivar) |&gt; \n  summarise(sev_med= median (sev2),\n            sev_mean = mean(sev2),\n            sd_mean = sd(sev2)) \n\n# A tibble: 3 × 4\n  cultivar sev_med sev_mean sd_mean\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved    1.64     2.16    1.82\n2 Local      17.2     18.7    11.1 \n3 Mixture     5.43     6.47    4.35\n\n\n\ncr |&gt; \ngroup_by(cultivar) |&gt; \n  summarise(sev_med= median (sev2),\n            sev_mean = mean(sev2),\n            sd_mean = sd(sev2)) \n\n# A tibble: 3 × 4\n  cultivar sev_med sev_mean sd_mean\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved    1.64     2.16    1.82\n2 Local      17.2     18.7    11.1 \n3 Mixture     5.43     6.47    4.35\n\n\n\nSeveridade por região e cultivar\nAgora, será gerado um histograma da severidade em função de duas variáveis independentes, a região e a cultivar. Nesse caso, será utlilizada a função facet_grid:\n\ncr |&gt; \n  ggplot(aes(x = sev2, fill = region))+\n  geom_histogram()+\n  facet_grid(region ~ cultivar)\n\n\n\n\n\n\n\nVisualizando os dados do conjunto\nO pacote ggthemes no R é uma extensão do ggplot2 que oferece uma ampla variedade de temas e estilos para personalizar gráficos.\n\nlibrary(ggthemes)\ncr |&gt; \n  ggplot(aes(x = sev2, fill = region))+\n  geom_histogram()+\n  facet_grid(region ~ cultivar)+\n  scale_fill_colorblind()\n\n\n\n\n\ncr |&gt; \n  ggplot(aes(x = sev2, fill = region))+\n  geom_histogram(color = \"black\")+\n  facet_grid(region ~ cultivar)+\n  scale_fill_manual(values = c(\"white\", \"blue\"))+\n  theme_minimal(base_size = 12)+\n  theme(legend.position = \"bottom\")+\n  labs(y = \"frequency\",\n       x = \"severity (%)\", fill = \"region\")\n\n\n\n#É possível notar que com a função facet_grid, o plot se torna mais harmônico."
  },
  {
    "objectID": "Aula3.html#criando-subconjuntos",
    "href": "Aula3.html#criando-subconjuntos",
    "title": "Importação, visualização e criação de subconjuntos",
    "section": "Criando subconjuntos",
    "text": "Criando subconjuntos\nPara criação de subconjuntos, serão utilizadas duas funções: select e filter :\n\n# filtra Oromia\n\ncr_oromia &lt;- cr |&gt; \n  select (farm, region, cultivar, sev2) |&gt; \n  filter(region == \"Oromia\")\n\ncr_oromia\n\n# A tibble: 165 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1   286 Oromia Mixture   7.63\n 2   287 Oromia Mixture   9.39\n 3   288 Oromia Mixture   1.30\n 4   289 Oromia Mixture   9.79\n 5   290 Oromia Local    18.5 \n 6   291 Oromia Mixture  13.2 \n 7   292 Oromia Mixture   5.60\n 8   293 Oromia Mixture   1.06\n 9   294 Oromia Local    17.6 \n10   295 Oromia Mixture  15.4 \n# ℹ 155 more rows\n\n# filtra SNNPR\ncr_pr &lt;- cr |&gt; \n  select (farm, region, cultivar, sev2) |&gt; \n  filter(region == \"SNNPR\")\n\ncr_pr\n\n# A tibble: 240 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 230 more rows\n\n\n\nVisualizando os subconjuntos graficamente:\n\np1 &lt;- cr_oromia |&gt; \n  ggplot(aes(cultivar,sev2, fill = cultivar))+ \n  geom_boxplot()+\n  labs(x = \"\", y= \"Severity (%)\") +\n  coord_flip()\n\n\np2 &lt;- cr_pr |&gt;  \n  ggplot(aes(cultivar,sev2, fill = cultivar))+ \n  geom_boxplot()+\n  labs(x= \"\", y= \"Severity(%)\") +\ncoord_flip()\n\n#Também é possível inverter o modo como o boxplot é plotado, utilizando a função coord_flip\n\n\n\nPara juntar gráficos em diferentes posicionamentos:\nUtliza-se o pacote patchwork uma ferramenta robusta para unir múltiplos gráficos gerados com ggplot2 em uma única disposição. Ele simplifica a elaboração de layouts complexos e personalizados, possibilitando a combinação de gráficos lado a lado, sobrepostos ou em matrizes.\n\nlibrary(patchwork)\n# Ao lado\np1 + p2\n\n\n\n# Acima \np1 / p2\n\n\n\n# Retirar a legenda duplicada\n(p1 + p2) +\n  plot_layout(guides = \"collect\")\n\n\n\n# Atribuir letras a cada gráfico\n(p1 / p2) +\n  plot_layout(guides = \"collect\", axes= \"collect\") +\n  plot_annotation(title = \"Coffe rust Ethiopia\", \n                  caption = \"source: vieira (2022)\",\n    tag_levels = \"A\")\n\n\n\np3 &lt;- cr_oromia |&gt; \n  ggplot(aes(x = sev2))+\n  geom_histogram()\n\np1 + inset_element(p3, left = 0.6, bottom = 0.6, right = 1, top = 1)\n\n\n\n\nPara o salvar o gráfico criado:\n\nggsave(\"patch1.png\", width = 5, height = 4)"
  },
  {
    "objectID": "Aula4.html",
    "href": "Aula4.html",
    "title": "Uso do datapasta e Tabela de contingência",
    "section": "",
    "text": "Durante a aula 4 , serão apresentados diversas operações com dados datapasta, para copiar e colar dados como vetores, data frames e tribbles. Também serão feitas tabelas de contingência e gráficos de barras para análise de dados categóricos, utilizando as funções count e tabyl do pacote janitor.\nInicialmente, serão instalados (datapasta e janitor) e carregados os pacotes que serão necessários durante esta aula."
  },
  {
    "objectID": "Aula4.html#pacotes-carregados",
    "href": "Aula4.html#pacotes-carregados",
    "title": "Uso do datapasta e Tabela de contingência",
    "section": "Pacotes carregados",
    "text": "Pacotes carregados\n\nlibrary(tidyverse)\nlibrary(datapasta)\nlibrary(janitor)\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "Aula4.html#pacote-datapasta",
    "href": "Aula4.html#pacote-datapasta",
    "title": "Uso do datapasta e Tabela de contingência",
    "section": "Pacote datapasta",
    "text": "Pacote datapasta\nO pacote datapasta amplia as capacidades do RStudio ao oferecer funcionalidades extras para a cópia e colagem de dados de diferentes origens. Isso permite a importação de dados de tabelas que possuam uma ou várias colunas.\n\nPaste as vector\nPara colar valores como um vetor, seleciona-se “Paste as vector”\n\n#usado para apenas uma coluna \n\nvet &lt;-c(\"comp\", \"9\", \"12.5\", \"10\", \"8\", \"13.2\", \"11\", \"10.8\", \"9.5\", \"10.8\", \"10.4\", \"13.72\", \"15.91\", \"15.7\", \"14.2\", \"15.9\", \"16.54\", \"18\", \"14.4\", \"16.41\", \"16\")\n\n\n\nPaste as tribble\nUma opção para criar um novo data frame é colar utilizando a opção “Paste as tribble”:\n\n#usado para mais de uma coluna \ndat2 &lt;- tibble::tribble(\n      ~trat, ~rep, ~comp,\n      \"Mg2\",   1L,     9,\n      \"Mg2\",   2L,  12.5,\n      \"Mg2\",   3L,    10,\n      \"Mg2\",   4L,     8,\n      \"Mg2\",   5L,  13.2,\n      \"Mg2\",   6L,    11,\n      \"Mg2\",   7L,  10.8,\n      \"Mg2\",   8L,   9.5,\n      \"Mg2\",   9L,  10.8,\n      \"Mg2\",  10L,  10.4,\n  \"control\",   1L, 13.72,\n  \"control\",   2L, 15.91,\n  \"control\",   3L,  15.7,\n  \"control\",   4L,  14.2,\n  \"control\",   5L,  15.9,\n  \"control\",   6L, 16.54,\n  \"control\",   7L,    18,\n  \"control\",   8L,  14.4,\n  \"control\",   9L, 16.41,\n  \"control\",  10L,    16\n  )\n\nUtilizando dados sobre os países:\n\nvisitas &lt;- tibble::tribble(\n             ~V1,              ~V2, ~V3,\n              1L,      \"Argentina\",  1L,\n              2L,        \"Austria\",  1L,\n              3L,        \"Bolivia\",  1L,\n              4L,     \"Cape Verde\",  1L,\n              5L,          \"China\",  1L,\n              6L,          \"Egypt\",  1L,\n              7L,        \"Finland\",  1L,\n              8L,          \"India\",  1L,\n              9L,          \"Italy\",  1L,\n             10L,       \"Malaysia\",  1L,\n             11L,       \"Pakistan\",  1L,\n             12L,         \"Poland\",  1L,\n             13L,      \"Singapore\",  1L,\n             14L,    \"Timor-Leste\",  1L,\n             15L,        \"Uruguay\",  1L,\n             16L,          \"Chile\",  2L,\n             17L,       \"Paraguay\",  2L,\n             18L,           \"Peru\",  2L,\n             19L,        \"Ecuador\",  3L,\n             20L,         \"France\",  3L,\n             21L,    \"Netherlands\",  4L,\n             22L,        \"Germany\",  5L,\n             23L,        \"Hungary\",  5L,\n             24L, \"United Kingdom\",  5L,\n             25L,       \"Colombia\",  8L,\n             26L,      \"(not set)\", 12L,\n             27L,          \"Spain\", 16L,\n             28L,         \"Angola\", 19L,\n             29L,  \"United States\", 23L,\n             30L,       \"Portugal\", 33L,\n             31L,     \"Mozambique\", 43L,\n             32L,         \"Brasil\", 43L)\n\n\nUtilizando a função “paste as tribble”, os dados presentes neste link (https://r4pde.net/temporal-fitting.html#entering-data - seção 10.4) serão importados:\n\n\n#os dados a seguir estão no formato largo\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  ) \n\n\nVisualizando os dados importados acima, é possível observar que eles estão no formato largo. Sendo preciso transformá-los para o formato longo.\nPara isso, será utilizada a função pivot_longer (tidyr). Indicamos quais colunas serão transformadas para o formato longo e atribuímos nomes às novas colunas:\n\n\n#Transfromar para o formato longo \n\npepper |&gt; \n  pivot_longer(2:4, \n               names_to = \"epidemic\",\n               values_to = \"inc\") |&gt; \n  \n  \n  #Criar grafico no ggplot (grafico de pontos com linhas)\n  ggplot(aes(t, inc, color = epidemic)) +\n  geom_point() +\n  geom_line()\n\n\n\n#para retirar a leganda \n\n#theme(legend.position = \"none\")\n\nCriação de gráfico de pontos com linhas utilizando o pivot_longer:\n\npepper |&gt; \n  pivot_longer(2:4, \n               names_to = \"epidemic\",\n               values_to = \"inc\") |&gt; \n  \n  #Criar grafico no ggplot (grafico de pontos com linhas)\n  ggplot(aes(t, inc, color = epidemic)) +\n  geom_point() +\n  geom_line() +\n  annotate(geom = \"text\",\n           x = 12,\n           y = 0.75, \n           label = \"1\") +\n    annotate(geom = \"text\",\n           x = 25,\n           y = 0.75, \n           label = \"2\") +\n  annotate(geom = \"text\",\n           x = 48,\n           y = 0.75, \n           label = \"3\")"
  },
  {
    "objectID": "Aula4.html#tabela-de-contingência",
    "href": "Aula4.html#tabela-de-contingência",
    "title": "Uso do datapasta e Tabela de contingência",
    "section": "Tabela de contingência",
    "text": "Tabela de contingência\nSerão construídas tabelas de contingências. Estas tabelas que permitem fazer contagens de elementos/ ocorrências de variáveis categóricas dentro de uma mesma coluna rapidamente.\nFormato .csv.\n\ncr &lt;- read_csv (\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n#restringir contagem para duas variaveis (region, zone), FORMATO LARGO\ncr |&gt; \n  count(region, zone)\n\n# A tibble: 9 × 3\n  region zone             n\n  &lt;chr&gt;  &lt;chr&gt;        &lt;int&gt;\n1 Oromia Bale            30\n2 Oromia Ilu AbaBora     45\n3 Oromia Jimma           45\n4 Oromia West Wellega    45\n5 SNNPR  Bench Maji      45\n6 SNNPR  Gedio           45\n7 SNNPR  Keffa           45\n8 SNNPR  Sheka           45\n9 SNNPR  Sidama          60\n\n\n\nUtilizando a função tabyl\nDentro do pacote janitor há a função tabyl, com objetivo de gera uma tabela de frequências:\n\nlibrary(janitor)\n\n# para descrever um conjunto, FORMATO LONGO \n\ncr |&gt; \n  tabyl(region, zone)\n\n region Bale Bench Maji Gedio Ilu AbaBora Jimma Keffa Sheka Sidama West Wellega\n Oromia   30          0     0          45    45     0     0      0           45\n  SNNPR    0         45    45           0     0    45    45     60            0\n\n\n\n# se inverte zona por region fica no formato largo \n\ncr |&gt; \n  tabyl(zone, region)\n\n         zone Oromia SNNPR\n         Bale     30     0\n   Bench Maji      0    45\n        Gedio      0    45\n  Ilu AbaBora     45     0\n        Jimma     45     0\n        Keffa      0    45\n        Sheka      0    45\n       Sidama      0    60\n West Wellega     45     0\n\n\n\ncr |&gt; \n  tabyl(cultivar, farm_management)\n\n cultivar Intensive Minimal Moderate Unmanaged\n Improved        83       0        0         0\n    Local         0      10        4       102\n  Mixture        82      59       65         0\n\n\n\n\nVisualizando\ncount é utilizada para contar o número de ocorrências de valores únicos em uma variável ou combinação de variáveis dentro de um conjunto de dados. Pertence ao pacote dplyr. Foi criado o gráficos de coluna. Faz o empilhamento das colunas. Padrão steck.\n\ncr |&gt;  \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management)) +\n  geom_col(position = \"stack\")\n\n\n\n\nGráfico de barras lado a lado. Alterando a posição (dodge):\n\n#para desemplilhar e colocar uma barra ao lado da outra\n\ncr |&gt;  \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management, label = n)) +\n  geom_col(position = \"dodge2\") +\n  scale_fill_colorblind()+\n  theme_bw()+\n  theme(strip.text.x = element_blank())+\n  facet_wrap(~cultivar, scales = \"free\") +\n  geom_text(position = position_dodge (width = 0.9))+\n  facet_wrap(~cultivar, scales = \"free_x\" )\n\n\n\n\n\n\nImportação de dados de planilha\nFormato online"
  },
  {
    "objectID": "Aula5.html",
    "href": "Aula5.html",
    "title": "Análise do conjunto de dados da prova",
    "section": "",
    "text": "Durante a aula 5, serão analisados e interpretados os valores das notas das duas primeiras atividades avaliativas da disciplina FIP 606 foi dado um conjunto de dados da prova:"
  },
  {
    "objectID": "Aula5.html#pacotes-carregados",
    "href": "Aula5.html#pacotes-carregados",
    "title": "Análise do conjunto de dados da prova",
    "section": "Pacotes carregados",
    "text": "Pacotes carregados\n\nlibrary(gsheet)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(patchwork)"
  },
  {
    "objectID": "Aula5.html#importando-dados",
    "href": "Aula5.html#importando-dados",
    "title": "Análise do conjunto de dados da prova",
    "section": "Importando dados",
    "text": "Importando dados\n\n#importação dos dados via planilha Google:\n\ndf1 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1092065531\")\n\ndf1$prova &lt;- as.factor(df1$prova)\n\n\nInicialmente foi feita uma análise dos dados importados (descrevendo o que tem em 3 colunas (prova, pontos e nota):\n\n\nglimpse(df1)\n\nRows: 44\nColumns: 3\n$ prova  &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ pontos &lt;dbl&gt; 10, 13, 12, 6, 14, 12, 14, 8, 14, 10, 10, 13, 9, 14, 9, 14, 12,…\n$ nota   &lt;dbl&gt; 71.40, 92.90, 85.70, 42.90, 100.00, 85.70, 100.00, 57.10, 100.0…\n\n\n\nUsando o summary foi observado a nota max e min entre as duas provas.\n\n\nsummary(df1$nota)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  42.90   68.75   85.70   79.40  100.00  100.00 \n\n\n\nFoi realizado o teste de média com a sumarização da mesma tanto para primeira avaliação quanto para a segunda:\n\n\n#Média \ndf1 |&gt; \ngroup_by(prova) |&gt; \n  summarize(inc_mean = mean(nota))\n\n# A tibble: 2 × 2\n  prova inc_mean\n  &lt;fct&gt;    &lt;dbl&gt;\n1 1         79.5\n2 2         79.3\n\n\n\nForam feitas média e mediana e foi observado que a dispersão dos dados é bem parecida tanto para prova1 quanto para prova2.\n\n\n#Média, mediana\n\ndf1 |&gt; \ngroup_by(prova) |&gt; \n  summarise(inc_med= median (nota), inc_mean = mean(nota), sd_mean = sd(nota)) \n\n# A tibble: 2 × 4\n  prova inc_med inc_mean sd_mean\n  &lt;fct&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 1        85.7     79.5    19.0\n2 2        84.4     79.3    19.7\n\n\n\nApesar dos dados terem uma distribuição bem similar, de forma visual podemos observar que os alunos foram melhores na prova2, quando comparado com a primeira prova, visto que as barras tem uma tendencia a aumentar depois da linha de marcação da média.\n\n\n#Filtrando prova 1\n prova1 &lt;- df1 |&gt; \n  select (prova, nota) |&gt; \n  filter(prova == \"1\")\n \n #Filtrando prova 2\n prova2 &lt;- df1 |&gt; \n   select (prova, nota) |&gt; \n  filter(prova == \"2\")\n \n p1 &lt;- prova1|&gt; \n  ggplot(aes(x = nota))+\n  geom_histogram(bins = 5, color = \"white\", fill = \"red\")+\n  facet_grid(~prova)+\n  theme_few(base_size = 12)+geom_vline(xintercept = 79.54, linetype = 2) + annotate(geom = \"text\", x = 75, y = 7.5, label = \"mean\")+ ylim(0,10)\n \n p2 &lt;- prova2|&gt; \n  ggplot(aes(x = nota))+\n  geom_histogram(bins = 5, color = \"white\", fill = \"darkgreen\")+\n  facet_grid(~prova)+\n  theme_few(base_size = 12)+geom_vline(xintercept = 79.54, linetype = 2) + annotate(geom = \"text\", x = 75, y = 7.5, label = \"mean\")+ ylim(0,10)\n \n p1+p2\n\n\n\n\n\nQuando se tem mais que 15 pontos usa-se o boxplot (usado quando se tem muita informação agregada), foram 22 notas na prova1 e 22 notas da prova2, demonstrando uma similaridade nos resultados das duas provas.\n\n\n# boxplot\n\ndf1 |&gt; \n ggplot(aes(factor(prova), nota))+ \n  geom_boxplot(color = \"black\", fill = \"skyblue\")+geom_jitter(width = 0.05)\n\n\n\n\n\nAbaixo pode-se observar a quantidade de pessoas que ficaram acima da média tanto na p1 e p2 quanto a diferença entre as notas acima da média nas duas provas.\n\n\n#OBSERVAÇÃO DE QUANTAS PESSOAS FICARAM ACIMA DA MÉDIA EM P1.\n\np1 &lt;- df1 |&gt; \n  filter(prova == 1, nota &gt; mean(nota)) |&gt; \n  nrow() / \ndf1 |&gt; \n  filter(prova == 1) |&gt; nrow() * 100\n\n# em p2 mais pessoas ficaram acima da média como pode-se observar. \np2 &lt;- df1 |&gt; \n  filter(prova == 2, nota &gt; mean(nota)) |&gt; \n  nrow() / \ndf1 |&gt; \n  filter(prova == 2) |&gt; nrow() * 100\n\n#difrença entre p1 e p2 \np1-p2\n\n[1] -4.545455\n\n\n\nCom isso foi plotado um gráfico com pontos das distribuições das notas, podendo-se contar os pontos, observando uma mínima diferença de uma nota acima da média em p2 quando comparada a p1 numericamente.\n\n\ndf1 |&gt; \n  ggplot(aes(y = nota, x = prova))+\n  geom_jitter(width = 0.36, size = 2, shape = 20, color = \"black\")+\n  theme_few()+ geom_vline(xintercept = 1.5, linetype = \"dotted\")+\n  ggtitle(\"Distribuição de notas de prova1 e prova2\")+\n  geom_hline(yintercept = mean(df1$nota),\n             linetype = \"dashed\",\n             color = 'red',\n             size = 0.75)\n\n\n\n\nConclusão:\nPodemos observar que numericamente levando em conta a média os alunos foram melhores na segunda prova em comparação com a primeira aproximadamente 5% (referente a nota de um aluno de diferença) levando em conta os números. Entretanto não foram realizados testes estatísticos para demonstrar, apenas as análises numéricas (contagem) e gráficas acima. Visualmente podemos observar que se tem uma tendência as barras estarem mais concentradas acima da média na prova2."
  },
  {
    "objectID": "Aula6e7.html",
    "href": "Aula6e7.html",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "",
    "text": "Durante a aula 6, utilizando a estatística inferencial. O $ é utilizado para puxar o dado de uma coluna dentro do conjunto de dados; já o ~ utiliza um fator em função do outro."
  },
  {
    "objectID": "Aula6e7.html#pacotes-carregados",
    "href": "Aula6e7.html#pacotes-carregados",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "Pacotes carregados",
    "text": "Pacotes carregados\n\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(multcomp)\nlibrary(multcompView)"
  },
  {
    "objectID": "Aula6e7.html#importando-dados",
    "href": "Aula6e7.html#importando-dados",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "Importando dados",
    "text": "Importando dados\n\n#Importar pacotes \n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")"
  },
  {
    "objectID": "Aula6e7.html#para-dois-grupos-diferentes-independentes",
    "href": "Aula6e7.html#para-dois-grupos-diferentes-independentes",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "Para dois grupos diferentes (independentes)",
    "text": "Para dois grupos diferentes (independentes)\nPara esse conjunto de dados, temos um fator com dois níveis: com e sem magnésio (Mg). Observamos que o magnésio tem um efeito redutor no tamanho da lesão, indicando que a aplicação de Mg está induzindo uma reação de resistência. O tamanho da lesão é maior no tratamento controle. Para publicar este trabalho, é necessário testar a hipótese de que “a suplementação de magnésio reduz o tamanho da doença” (hipótese experimental), enquanto a hipótese nula afirma que as médias não diferem (hipótese estatística). No gráfico, vemos um boxplot simétrico com uma diferença clara entre as medianas, sugerindo a possibilidade de uma diferença significativa. A simetria do boxplot já indica uma possível normalidade dos dados, o que facilita a visualização.\n\n#vizualização\nmg |&gt; \n  ggplot(aes(trat, comp))+\n  geom_boxplot()\n\n\n\n#demonstra o efeito da suplementação de magnesio que induz a resistencia, visando testar uma hipotese cientifica é que com a suplementação induz a resistencia \n#a hipotese nula é que o valor das populações são iguais.  \n\nTeste T, usado para dois grupos independentes, primeiro existe se existe uma normalidade, dendencia ou independencia e se as variancias são homogeneas. (teste T não pareado), quem inventou o test t? student\nPara verificar se há diferença ou não, utilizaremos o teste t, que é um teste simples geralmente usado para comparar dois grupos. Se houver mais de dois grupos, seria necessário fazer comparações par a par. Assumimos a normalidade dos dados e a homogeneidade das variâncias, pois temos um número pequeno de tratamentos. No experimento, 10 plantas receberam um tratamento e 10 plantas receberam outro, o que as torna variáveis independentes.\n\n#teste T \n\n#longo para o largo (ver o formato antes tem que larogo)\nmg2 &lt;- mg |&gt; \n  pivot_wider(names_from = trat,\n              values_from = comp)\n\nteste1 &lt;- t.test(mg2$Mg2, mg2$control, )\n\n#interpretação: o teste T - ligado ao erro padrão, a probabilidade é pequena pelo fato do p valor ter dado p-value = 2.423e-07 que nesse caso é menor que 0.5 rejeitando a hipotese nula. conclunido que o teste t esta correto. o intervalo de confiança é a diferença verdadeira entre as médias, dado pela ordem de montagem do teste. \n\n\nVerificação das premissas\n\n#testar a normalidade \nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\n#testar a normalidade hipotese nula, dizendo que a distribuição é normal, maior que 0.5 normalidade. \n\nhist(mg2$control)\n\n\n\n#faz-se o histograma para saber se é normal \n\nHistogramas: Uma forma de se avaliar a normalidade visualmente.\nA avaliação também pode ser feita utilizando testes estatísticos. Nesse caso, será aplicada uma função nativa do R que é o shapiro.test:\n\n#testar a normalidade para mg \nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\n#demosnta uma distribuição normal acima de 0.5\n\n\nhist(mg2$Mg2)\n\n\n\n#os dados possuem distribuição normal. Os histogramas possuem formato típico de um conjunto de dados normais. Nos Q-Q Plots, é possível notar que os pontos estão próximo a linha de normalidade. E pelos testes de Shapiro Wilk, não se rejeita a hipótese nula (de normalidade), já que valor de P é maior que o nível de significância adotado (⍺ = 5%).\n\n\n\nTeste de homogeneidade\nPara avaliar a homogeneidade vai se utilizar a função var.test:\n\n#teste F que compara duas variancias\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nQ-Q Plot pode observar a normalidade:\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\n\n\nlibrary(report)\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])"
  },
  {
    "objectID": "Aula6e7.html#para-dois-grupos-dependentes",
    "href": "Aula6e7.html#para-dois-grupos-dependentes",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "Para dois Grupos dependentes",
    "text": "Para dois Grupos dependentes"
  },
  {
    "objectID": "Aula6e7.html#importando-dados-1",
    "href": "Aula6e7.html#importando-dados-1",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "Importando dados",
    "text": "Importando dados\n\n#para dois grupos, vai usar o test t pareado \n\n#importar o pacote de dados:\n\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nPara demonstrar a aplicação do teste t pareado (ou para amostras dependentes), utilizaremos um conjunto de dados contendo os resultados de avaliação de doenças antes e após o uso de uma escala de doenças. O objetivo será determinar se o uso da escala tem algum efeito sobre as avaliações.\n\nlibrary(dplyr)\nescala2 &lt;- escala |&gt; \n  dplyr::select(assessment, rater, acuracia) |&gt; \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\nescala2\n\n# A tibble: 10 × 3\n   rater Unaided Aided1\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 A        0.81   0.91\n 2 B        0.72   0.91\n 3 C        0.4    0.91\n 4 D        0.82   0.96\n 5 E        0.75   0.96\n 6 F        0.45   0.9 \n 7 G        0.81   0.85\n 8 H        0.78   0.88\n 9 I        0.78   0.95\n10 J        0.5    0.94\n\n\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n\n\n\n#neste caso sugere falta de normalidade\n\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\n#regeita a hipotese nula e aceita a falta de normalidade pq p-value = 0.007155. \n\n\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n# se a variancia é homogenea ou não \n\n\nt.test(escala2$Aided1, escala2$Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n\n#teste de comparação de dois grupos de media, com 3 ou mais usa-se anova\n\nEquivalente ao não parametico do teste t.\n\nwilcox.test(escala2$Aided1,\n            escala2$Unaided, \n            paired = TRUE) \n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n#Teste não paramétrico: Utilizado porque o teste de shapiro wilk não deu a normalidade dos dados. Geralmente, os testes paramétricos têm mais poder, mas utilizar o paramétrico ou o não paramétrico está correto nos dois tipos de testes desde que você siga as premissas para a utilização de cada teste."
  },
  {
    "objectID": "Aula6e7.html#para-três-grupos-ou-mais",
    "href": "Aula6e7.html#para-três-grupos-ou-mais",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "Para três grupos ou mais",
    "text": "Para três grupos ou mais"
  },
  {
    "objectID": "Aula6e7.html#importando-dados-2",
    "href": "Aula6e7.html#importando-dados-2",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "Importando dados",
    "text": "Importando dados\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\nA anova vai testar se existe diferença entre as médias, testando a variabilidade dentro do grupo e entre os grupos. Usou o geom_jitter por que tem menos de 10 repetições e é legal visualizar os dados um a um.\n\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.05)\n\n\n\n#menos de oito (6 pontos) - geom_jitter\n\n\n#Com o gráfico a seguir, não é possível observar visualmente se há ou não diferença entre as médias das espécies. A distribuição não é homogênea.Demonstra que variabilidade dentro de cada grupo é grande.\n\nSe as médias não diferem, não faz mais sentido continuar o teste de comparação de médias.\n\n#anova \n\n\nm1 &lt;- lm(tcm ~ especie -1 , data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\n#segundo o teste da anova não há difrença estatistica entre as especies apenas numerica, todas com uma taxa micelial muito alta. \n\nPara manter o mesmo tema:\n\ntheme_set(theme_bw())\n\n#manter o mesmo tema \n\nO Emmeans define as médias diretamente. Definindo um teste estatístico para comparação do crescimento.\n\nlibrary(emmeans)\nmedias1 &lt;- emmeans(m1, ~ especie)\nmedias1\n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\nlibrary(multcomp)\n\n\n\nlibrary(multcompView)\n\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nhist(m1$residuals)\n\n\n\n\n\nVerificação das premissas\nO teste de shapiro executado indica normalidade dos resíduos. P valor = 0,8782. Não rejeita a hipótese.\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\n#não rejeita a hipotese p-value = 0.8782.\n\no bartlett.test testa se várias amostras possuem variâncias iguais. Esse teste é útil quando você está realizando análises que assumem a homogeneidade das variâncias.\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\n\nVerificação das premissas\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)\n\n\n\n\nDurante a aula 7 do dia 24/04, vamos continuar a aula anterior:\n\ninseticida &lt;- InsectSprays\n\nlibrary(tidyverse)\n\ninceticida &lt;- InsectSprays\ninceticida |&gt; \n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n#anova com um fator ou seis niveis de fator \n\nExploração do conjunto de dados - variavel numerica discreta\n\ninceticida |&gt; \nggplot(aes(spray, count))+\n  geom_boxplot()+\n  geom_jitter(width = 0.05)\n\n\n\n#observando podemos inferir que as variâncias são heterogêneas. Tratamento com maior variabilidade (F), com menos variabilidade (C) e que possui outlier.\n\nAjusta a nova e trabalha com os residuos da anova e ai parte pa os testes, usando performace e darman. O modelo de ANOVA é ajustado, e trabalhamos com os resíduos da ANOVA, e não com os dados originais, e aí são aplicados os testes.\n\nm1 &lt;- lm(count ~ spray, \n         data = inceticida)\nm1\n\n\nCall:\nlm(formula = count ~ spray, data = inceticida)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n    14.5000       0.8333     -12.4167      -9.5833     -11.0000       2.1667  \n\n\n\nsummary(m1)\n\n\nCall:\nlm(formula = count ~ spray, data = inceticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nhist(m1$residuals)\n\n\n\n\nshapiro.test mostra que significativo não é normal, se for significativo é normal.\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n\n\nPremissa importante: tem maior peso na decisão - homocedasticidade.\n\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\n\n\n#Quando os pontos acompanham a linha de tendência central, acusa que os dados são normais.\n\no que é mais importante a normalidade ou variancias homogeneas o que é a violação mais problematica?\nhomocedasticidade(?)\nQuando temos dados de contagem normalmente a raiz é uma boa opção.\n\n\nBartlett - test\nÉ uma função utilizada para testar a homogeneidade das variâncias entre diferentes grupos. Ele verifica se várias amostras possuem variâncias iguais.\n\nbartlett.test(count ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\n\n\n\nVerificação das premissas\nNeste caso não atendeu!\n\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\n\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\nSe não atendeu pode se fazer a transformação de dados:\n\nExtrair a raiz quadrada (apropriada pra dados de contagem); Ou usar log.\n\n\n\nAlternativa 01 - Extração da Raiz quadrada\n\ninseticida &lt;- inseticida |&gt; \n   mutate(count2 = sqrt(count))\n\ninseticida |&gt; \n  ggplot(aes(spray, count2))+\n  geom_boxplot()+\n  geom_jitter()+\n  theme_bw()\n\n\n\n#normalidade não é um problema aqui, e sim a variância.\n\ncom a ajuda dos resultados abaixo é possível inferenciar que os problemas de normalidade foram resolvidos.\n\nm2 &lt;- lm (count2 ~ spray, data = inseticida)\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nhist(m2$residuals)\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\nbartlett.test(count2 ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\n\n\nVerificação das premissas\n\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\n\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\n\n\nplot(simulateResiduals(m2))\n\n\n\n\nAlternativas para visualização das comparações de médias\n\nÉ possível observar que a transformação dos dados resolveu a dispersão das variâncias. Podemos continuar com o teste. O resultado foi não significativo. Podemos seguir com a estimativa das médias. A função pwpp (emmeans) constrói uma plotagem de valores de probabilidade associados as comparações pareadas das médias marginais estimadas.\n\nlibrary(emmeans)\nm2_medias &lt;- emmeans(m2, ~ spray)\nplot(m2_medias)\n\n\n\nlibrary(multcomp)\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\n\n\n\n\n\nAlternativa 2 - Teste não paramétrico - Sem transformar\n\nlibrary(agricolae)\nkruskal.test(count ~ spray, \n             data = inceticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\n#rejeita \n#ipotese nula é que as médias são iguais o que demonstra que rejeita - com 3 grupos ou mais \n\nRejeita-se a hipótese nula, porque o P é menor que 0,05.\n\nm3 &lt;- kruskal(inseticida$count,\n        inceticida$spray, \n        group = TRUE)\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inceticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n#da a media dos tratamentos e um ranking para fazer a estatistica, calculando os agrupamentos. 3 grupos ranqueados. o não parametrico deu o mesmo resultado que o modelo transformado. podendo partir para a alternativa 3 assumindo que a distribuição é de acordo com os dados podendo ser poason (modelo linear generalizado - mais moderno)\n\n\n\nAlternativa 3 - GLMs\n\nm4 &lt;- glm(count ~ spray,\n          family = poisson, data = inseticida)\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\nlibrary(car)\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nplot(simulateResiduals(m4))\n\n\n\n\n\nm4_medias &lt;- emmeans(m4, ~spray,\n                     type = \"response\")\ncld(m4_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nvalor original - observação resposta original\nanova - testo pressupostos\nalternativa 1 - trasformação\nbusca normalização\na2- não parametrico\na3- GLMs\nfaz tudo isso para cada variavel\n\n\nTransformação BOX-COX\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inceticida$count+0.1 ~1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\ninceticida$count3 &lt;- (inceticida$count ^  lambda - 1) / lambda\ninceticida$count3\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\n#mandeira de tranformar \n\n\nNovo conjunto uma anova para dois fatores.\n\n\n\nANOVA Fatorial"
  },
  {
    "objectID": "Aula6e7.html#importando-dados-3",
    "href": "Aula6e7.html#importando-dados-3",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "Importando dados",
    "text": "Importando dados\n\nli &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\n\nli |&gt; \n  ggplot(aes(factor(dose), severity, color = factor(dose)))+\n  geom_jitter(whidth = 0.1)+\n facet_wrap(~treat)\n\n\n\n#vizualização"
  },
  {
    "objectID": "Aula6e7.html#modelo-fatorial-two-way-anova",
    "href": "Aula6e7.html#modelo-fatorial-two-way-anova",
    "title": "Estatística inferencial: ANOVA e teste de médias",
    "section": "Modelo fatorial (two-way anova)",
    "text": "Modelo fatorial (two-way anova)\n\nmf &lt;- lm(severity ~ treat * dose, \n         data = li)\nmf\n\n\nCall:\nlm(formula = severity ~ treat * dose, data = li)\n\nCoefficients:\n           (Intercept)       treatTebuconazole                    dose  \n                0.3728                 -0.3515                 -0.1613  \ntreatTebuconazole:dose  \n                0.1608  \n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#demostra que a interassão é significativa, as doses estão diretamente ligadas aos tratamentos. \n\n\nVerificação das premissas\n\nplot(simulateResiduals(mf))\n\n\n\n#não teve problema \n\n\n\nCompraçaõ de medias, dentro das linhas e dentro das colunas\n\nmf_medias &lt;- (mf ~ treat | dose)\n#cld(mf_medias)\n\n#comparou coluna \n\n\n# comprar as linhas \nmf_medias &lt;- emmeans(mf, ~ dose | treat)\ncld (mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula8.html",
    "href": "Aula8.html",
    "title": "Transformações, ANOVA e teste de média",
    "section": "",
    "text": "Durante a aula 8, foram trabalhados dados para apresender a fazer transformações, ANOVA e teste de médias."
  },
  {
    "objectID": "Aula8.html#pacotes-carregados",
    "href": "Aula8.html#pacotes-carregados",
    "title": "Transformações, ANOVA e teste de média",
    "section": "Pacotes carregados",
    "text": "Pacotes carregados\n\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(patchwork)\nlibrary(r4pde)\nlibrary(emmeans)\nlibrary(performance)\nlibrary(multcomp)\nlibrary(agricolae)\nlibrary(epifitter)"
  },
  {
    "objectID": "Aula8.html#importando-dados",
    "href": "Aula8.html#importando-dados",
    "title": "Transformações, ANOVA e teste de média",
    "section": "Importando dados",
    "text": "Importando dados\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nTransformar para fator = preciso tranformar fator, pois esta como número.\n\nsoja &lt;- soja |&gt; \n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))\n\nis.vector(soja)\n\n[1] FALSE\n\nis.factor(soja$TRAT)\n\n[1] TRUE"
  },
  {
    "objectID": "Aula8.html#visualização-dos-dados",
    "href": "Aula8.html#visualização-dos-dados",
    "title": "Transformações, ANOVA e teste de média",
    "section": "visualização dos dados",
    "text": "visualização dos dados\nPara visualização dos dados das variáveis dependentes (DFC, FER e PROD), serão construídos gráficos de pontos (ggplot: geom_jitter) acrescido do intervalo de confiança. Para a apresentação do intervalo de confiança, será utilizada a função stat_summary (fun.data), com o argumento \"mean_cl_boot\".\nPara visualizar os dados, para variavel DFC.\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC)) +\n  geom_jitter(which = 0.05)\ndfc\n\n\n\n\nPara variavel FER:\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER)) +\n  geom_jitter(which = 0.05)\ndfc\n\n\n\n\nPara variavel prod:\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD)) +\n  geom_jitter(which = 0.05)\ndfc\n\n\n\n\nPara juntar os 3 graficos:\n\n(dfc+fer+prod)\n\n\n\n\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC)) +\n  geom_jitter(width = 0.05, color = \"gray70\") +\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\")\n\ndfc\n\n\n\n\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER)) +\n  geom_jitter(width = 0.05, color = \"gray70\") +\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\")\n\ndfc\n\n\n\n\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD)) +\n  geom_jitter(width = 0.05, color = \"gray70\") +\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\")\n\ndfc\n\n\n\n\n\n(dfc+fer+prod)\n\n\n\n\n\nANOVA DFC\n\naov_dfc &lt;- lm(DFC ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Pvalor indicando com *** e o valor baixo, indiccando que o efeito do tratamento é extremamente significativo. Para blocos, não foi significativo. Pode seguir as análises por que pelo menos uma das médias difere uma da outra, agora temos que saber se podemos confiar na anova e testar as suas premissas de normalidade e homosdasticidade.\n\n\nVerificação das premissas\n\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\n\n\n\n\nComparação de médias\nPara comparação de médias o modelo gerado acima será aplicado à função emmeans para criação de um novo objeto. Essa função estima uma média com base no modelo, logo algumas vezes pode não ser igual a média aritmética.\n\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\n\nNa função pwpm, há três informações úteis. Na diagonal, é apresentado o valor médio estimado para cada tratamento. Acima da diagonal, são plotados os valores de probabilidade, relacionados ao teste de Tukey, referentes às comparações múltiplas entre tratamentos. Abaixo da diagonal, há a diferença de valores médios entre os tratamentos.\n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\n\ncld(medias_dfc, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  A    \n 7      4.08 0.322 21     3.41     4.74  A    \n 5      4.20 0.322 21     3.53     4.87  A    \n 8      4.58 0.322 21     3.91     5.24  AB   \n 4      4.75 0.322 21     4.08     5.42  AB   \n 3      6.05 0.322 21     5.38     6.72   BC  \n 2      6.42 0.322 21     5.76     7.09    C  \n 1     10.88 0.322 21    10.21    11.54     D \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nANOVA fer\n\naov_fer &lt;- lm(FER ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nVerificação das premissas\n\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\ncheck_normality(aov_fer)\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\n\n\n## Tranformação por logarítimo\n\nsoja &lt;- soja |&gt; \n  mutate(FER2 = log(FER))\n\naov_fer2 &lt;- lm (FER2 ~ TRAT + BLOCO, data = soja)\n\nanova(aov_fer2)\n\nAnalysis of Variance Table\n\nResponse: FER2\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 11.5210 1.64585 42.9665 4.838e-11 ***\nBLOCO      3  0.2064 0.06880  1.7961    0.1788    \nResiduals 21  0.8044 0.03831                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(aov_fer2)\n\nOK: residuals appear as normally distributed (p = 0.255).\n\ncheck_heteroscedasticity(aov_fer2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.035).\n\n#A transformação foi suficiente para normalizar os valores do resíduo, no entanto, ainda há heterocedasticidade.\n\n\n\n\nTransformação - Box-Cox\n\nb &lt;- boxcox(lm(soja$FER ~1))\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)] \nlambda\n\n[1] -1.555556\n\n\n\nsoja$FER &lt;- (soja$FER^lambda -1)/lambda\nsoja$FER\n\n [1] 0.6350214 0.6372165 0.6385564 0.6356880 0.6078962 0.5684565 0.6175462\n [8] 0.5902763 0.6032606 0.5512801 0.4882973 0.5684565 0.5684565 0.5264644\n[15] 0.4882973 0.5264644 0.5512801 0.5512801 0.5264644 0.5264644 0.5512801\n[22] 0.4882973 0.5264644 0.5264644 0.5512801 0.5512801 0.5264644 0.5512801\n[29] 0.5684565 0.5512801 0.5264644 0.5512801\n\n\n\nNovo modelo - Após transformação\n\naov_fer2 &lt;- lm(FER ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_fer2)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df   Sum Sq   Mean Sq F value    Pr(&gt;F)    \nTRAT       7 0.041641 0.0059488 12.9020 2.436e-06 ***\nBLOCO      3 0.005895 0.0019649  4.2616   0.01687 *  \nResiduals 21 0.009683 0.0004611                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Para os dados transformados por Box-Cox, o fator fixo TRAT continua possuindo efeito significativo, logo há algum tratamento que difere dos demais. Para o fator BLOCO, não houve efeito já que não há diferença significativa entre eles.\n\n\n\nVerificação das premissas\n\ncheck_heteroscedasticity(aov_fer2)\n\nOK: Error variance appears to be homoscedastic (p = 0.872).\n\ncheck_normality(aov_fer2)\n\nOK: residuals appear as normally distributed (p = 0.787).\n\n#Os testes demonstram que a transformação de Box-Cox foi suficiente para conferir normalidade aos resíduos e homogeneidade de variância entre os grupos.\n\n\n\nComparação de médias\n\nmedias_fer2 &lt;- emmeans(aov_fer2, ~ TRAT)\nmedias_fer2\n\n TRAT emmean     SE df lower.CL upper.CL\n 1     0.637 0.0107 21    0.614    0.659\n 2     0.596 0.0107 21    0.574    0.618\n 3     0.553 0.0107 21    0.530    0.575\n 4     0.527 0.0107 21    0.505    0.550\n 5     0.539 0.0107 21    0.517    0.561\n 6     0.523 0.0107 21    0.501    0.545\n 7     0.545 0.0107 21    0.523    0.567\n 8     0.549 0.0107 21    0.527    0.572\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\n\n\ncld(medias_fer2, Letters = LETTERS)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6     0.523 0.0107 21    0.501    0.545  A    \n 4     0.527 0.0107 21    0.505    0.550  A    \n 5     0.539 0.0107 21    0.517    0.561  A    \n 7     0.545 0.0107 21    0.523    0.567  A    \n 8     0.549 0.0107 21    0.527    0.572  AB   \n 3     0.553 0.0107 21    0.530    0.575  AB   \n 2     0.596 0.0107 21    0.574    0.618   BC  \n 1     0.637 0.0107 21    0.614    0.659    C  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nANOVA PROD\n\naov_prod &lt;- lm(PROD ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Para o fator fixo TRAT, há efeito significativo, logo há algum tratamento que difere dos demais. Para o fator BLOCO, não houve efeito já que não há diferença significativa entre eles.\n\n\n\nVerificação das premissas\n\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\n#homegenidade de variancia e heteroscedasticidade é a mesma coisa  \ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\n\n\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\n#Os testes mostram que os resíduos são normalmente distribuídos e que há homogeneidade de variâncias entre os grupos. Assim, é possível continuar a comparação de médias.\n\n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\n\ncld(medias_prod, Letters = LETTERS)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  A    \n 2      4935 201 21     4516     5354  AB   \n 8      5078 201 21     4659     5497  AB   \n 3      5110 201 21     4691     5529  AB   \n 5      5122 201 21     4703     5541  AB   \n 7      5128 201 21     4709     5546  AB   \n 4      5140 201 21     4721     5559  AB   \n 6      5256 201 21     4837     5675   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\ndf_prod &lt;- data.frame(medias_prod)\ndf_prod |&gt; \n  \n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.1)+\nannotate (geom = \"text\", x = 1.2, y = 4200,\n         label = \"A\")\n\n\n\n#Gráfico com médias e intervalo de confiança, uma maneira visual de apresentar os resultados."
  },
  {
    "objectID": "Aula8.html#conjunto-de-dados-couve",
    "href": "Aula8.html#conjunto-de-dados-couve",
    "title": "Transformações, ANOVA e teste de média",
    "section": "CONJUNTO DE DADOS COUVE",
    "text": "CONJUNTO DE DADOS COUVE"
  },
  {
    "objectID": "Aula8.html#importando-dados-1",
    "href": "Aula8.html#importando-dados-1",
    "title": "Transformações, ANOVA e teste de média",
    "section": "Importando dados",
    "text": "Importando dados\n\ncouve &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\n\nPara construção de uma curva de progresso da doença usaremos como exemplo um conjunto de dados que descreve diferentes métodos de irrigação (variável independente, um fator, 2 níveis) e seu efeito sobre a severidade (variável dependente) ao longo dos dias.\n\ncov &lt;- couve |&gt; \n  ggplot(aes(day, severity)) +\n   geom_point(which = 0.05)+\n  facet_wrap(~~ Irrigation)\ncov\n\n\n\n\nFoi criada uma figura com dois gráficos. Um para cada nível do fator “Irrigation”:\n\ncouve |&gt; \n  group_by(day, Irrigation) |&gt; \n  summarise(mean_sev = mean(severity)) |&gt; \n  ggplot(aes(day, mean_sev)) +\n   geom_point(which = 0.05)+ \n  geom_line()+\n  facet_wrap(~~ Irrigation)\n\n\n\n\n\nCálculo da área abaixo da curva de progresso da doença\nPara o cálculo da área abaixo da curva de progresso da doença (AACPD, ou “area under the disease progress curve”, AUDPC), será criado um novo dataframe. Para isso, será feito o agrupamento (group_by) das variáveis em função do tratamento (”Irrigation”) e das repetições (“rep”). Em seguida, será utilizada a função summarise para o cálculo da AACPD (função AUDPC, pacote epifitter).\n\n#AACPD\n\ncouve2 &lt;- couve |&gt; \n  group_by(Irrigation, rep) |&gt; \n  summarise(aacpd = AUDPC(day, severity))\n\n\n\nANOVA\n\nm_couve &lt;- lm(aacpd ~ Irrigation + factor(rep), data = couve2)\nanova(m_couve)\n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#A ANOVA mostra que não há diferença entre as áreas.\n\n\n#coeficiente de variação\n#muito baixo \n\ncv.model(m_couve)\n\n[1] 1.097572"
  },
  {
    "objectID": "Aula9e10.html",
    "href": "Aula9e10.html",
    "title": "Experimento fatorial e ajuste de modelos - Análise de correlação",
    "section": "",
    "text": "Durante a aula 9,"
  },
  {
    "objectID": "Aula9e10.html#pacotes-carregados",
    "href": "Aula9e10.html#pacotes-carregados",
    "title": "Experimento fatorial e ajuste de modelos - Análise de correlação",
    "section": "Pacotes carregados",
    "text": "Pacotes carregados\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(performance)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(r4pde)\nlibrary(drc)"
  },
  {
    "objectID": "Aula9e10.html#importando-dados",
    "href": "Aula9e10.html#importando-dados",
    "title": "Experimento fatorial e ajuste de modelos - Análise de correlação",
    "section": "Importando dados",
    "text": "Importando dados\n\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")"
  },
  {
    "objectID": "Aula9e10.html#visualização-dos-dados",
    "href": "Aula9e10.html#visualização-dos-dados",
    "title": "Experimento fatorial e ajuste de modelos - Análise de correlação",
    "section": "visualização dos dados",
    "text": "visualização dos dados\n\nmilho |&gt; \n  ggplot(aes(method,index))+\n  geom_jitter(which = 0.1, alpha = 0.2)+\n  facet_wrap(~ hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color = \"blue\")\n\n\n\n\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n\nmix2 &lt;- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), data = milho)\n\nanova (mix2)\n\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 2.14415 0.42883  3.0632\nmethod           1 0.54438 0.54438  3.8886\nblock            3 0.01004 0.00335  0.0239\nhybrid:method    5 1.87331 0.37466  2.6762\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\n\n\nplot(simulateResiduals(mix2))\n\n\n\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n\n\n\nhist(residuals(mix2))\n\n\n\n\n\nmedias_milho &lt;- emmeans(mix2,\n                        ~ hybrid | method,\n                        type = \"response\")\nmedias_milho\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nmedias_milho2 &lt;- emmeans(mix2,\n                         ~ method | hybrid,\n                         type = \"response\")\nmedias_milho2\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\n\n\ncld(medias_milho2, Letters = LETTERS)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  A    \n pin        25.0 12.1 6084     6.84     54.4  A    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  A    \n silk       26.0 12.4 6084     7.42     56.0  A    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  A    \n silk       21.3 11.2 6084     5.00     48.9  A    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  A    \n pin        37.1 14.8 6084    13.79     71.8   B   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  A    \n pin        31.7 13.7 6084    10.57     64.2  A    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  A    \n pin        19.4 10.7 6084     4.10     46.0  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nmix3 &lt;- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), data = milho)\n\nanova (mix3)\n\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 2.14415 0.42883  3.0632\nmethod           1 0.54438 0.54438  3.8886\nblock            3 0.01004 0.00335  0.0239\nhybrid:method    5 1.87331 0.37466  2.6762\n\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\n\nOUTR O PACOTE: estande\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\n\n   estande |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_jitter(which = 0.1, alpha = 0.3)+\n  facet_wrap(~ exp)+\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color = \"black\")+\n     geom_smooth(method = \"lm\", se = F)\n\n\n\n\nexperimento 1\n\nexp1 &lt;- estande |&gt; \n  filter(exp == 1)\n\nexp1 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(se = F)\n\n\n\n\n\n#MODELO LINEAR\nlm1 = lm(nplants ~ trat,\n         data = exp1)\n\nsummary (lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\nexperimento 2\n\nexp2 &lt;- estande |&gt; \n  filter(exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\",\n              formula = y~poly(x,2),\n              color = \"red\")+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n#Modelo de primeira ordem\nlm2 &lt;- lm(nplants~trat,\n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nhist(residuals(lm2))\n\n\n\n# Nodelo de segunda ordem\nexp2$trat2 &lt;- exp2$trat^2\n\nexperimento 3\n\nexp3 &lt;- estande |&gt; \n  filter(exp == 3)\n\nexp3 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(se = F) #method = \"lm\")\n\n\n\n\n\nlm3 &lt;- lm(nplants~trat + trat2,\n          data = exp2)\n\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\nhist(residuals(lm3))\n\n\n\n\n#comparação de modelos diferente usando os mesmos dados\nusando modelo linear generaliazado\n\n#glm2 &lt;- glm(nplants ~ trat, family = gaussian, data = exp2)\n#summary(glm2)\n\n#AIC(glm2)\n\nglm2b &lt;- glm(nplants ~ trat, family = \"poisson\", data  = exp2)\nsummary(glm2b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.134189   0.037583 110.003  &lt; 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nglm2b &lt;- glm(nplants ~ trat, family = poisson(link = \"log\"),\n             data = exp2)\nsummary(glm2b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.134189   0.037583 110.003  &lt; 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm2b)\n\n[1] 210.2353\n\n\nAIC menor é o melhor modelo ajustado.\n\nwm &lt;- WhiteMoldSoybean\n\n\nwm |&gt; \n  ggplot(aes(inc, yld))+\n  geom_point()+ \n  facet_wrap(~ study)+\n  theme_minimal()\n\n\n\n\n\nmofo1 &lt;- lm(yld ~ inc,\n            data = wm)\n#intercepto pordutividade quando a incidencia é zero, inc é o slope com 10% de incidencia esta perdendo 90kg. \nsummary(mofo1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\n\nwm |&gt; \n  ggplot(aes(inc, yld, group = factor(study)))+\n  geom_point()+\n  #facet_wrap(~ study)+\n  theme_minimal()+\n  geom_smooth(method = \"lm\", se = F)\n\n\n\nmofo1 &lt;- lm(yld ~ inc,\n            data = wm)\nsummary(mofo1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\n\nlibrary(broom)\nfit_all &lt;- wm |&gt; \n  group_by(study) |&gt; \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\nfit_all\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\n\n\nfit_all |&gt; \n  filter(term == \"(intercept)\") |&gt; \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"slope\", y = \"frequency\")\n\n\n\n\n\nlibrary(patchwork)\n\nAula 10 - 29/05\n\n#pacotes \nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(AgroR)\nlibrary(corrplot)\n\n\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\nr2: coeficiente de determinação o quento da variação de y explicada pelo x\ncoenficiente de correlação: a força de associação entre x e y\n\nimgs1 &lt;- imgs|&gt; \n  ggplot(aes(Assess, LeafDoctor))+\ngeom_point()+ geom_smooth(method = \"lm\")\n\n\nimgs2 &lt;- imgs|&gt; \n  ggplot(aes(Assess, ImageJ))+\ngeom_point()+geom_smooth(method = \"lm\")\n\n\nimgs3 &lt;- imgs |&gt; \n  ggplot(aes(LeafDoctor, ImageJ))+\ngeom_point()+geom_smooth(method = \"lm\")\n\n\nimgs1 + imgs2 + imgs3\n\n\n\n\n\n#matriz de correlação \nimgs2 &lt;- imgs |&gt; \n  dplyr::select(3:5)\n\n  corgraph(imgs2)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\n\ncor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\n  cor(imgs$Assess, imgs$LeafDoctor)\n\n[1] 0.9666367\n\n\n\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"number\", type = \"upper\")\n\n\n\n\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\n\ncampo2 &lt;- campo |&gt; \n  dplyr::select(DFC, FER, PROD)\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\n\ncampo |&gt; \n  ggplot(aes(DFC, PROD))+\n  geom_jitter()\n\n\n\n\n\npyra &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\n\npyra2 &lt;- pyra |&gt; \n  group_by(code, dose) |&gt; \n  summarise(mean_germination = mean(germination))\n\npyra2 |&gt; \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  facet_wrap(~code)\n\n\n\n\n\nisolado165 &lt;- pyra2 |&gt; filter(code == \"165\")\n\ndrc1 &lt;- drm(mean_germination ~ dose, data = isolado165,\n            fct = LL.3()) \n\nAIC(drc1)\n\n[1] 31.55522\n\nplot(drc1)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Saudações, seja muito bem-vindo!",
    "section": "",
    "text": "Olá!!! Eu me chamo Iago Vieira, esse é o site destinado ao meu caderno de aulas da disciplina FIP 606, contendo todas as aulas descritas, por favor, sinta-se à vontade para conhecer o mundo R!\n\n\n\n\n\n\nSobre mim:\nEngenheiro Agrônomo pela Universidade Federal de Viçosa - campus Rio Paranaíba. Possui experiência em colaboração em trabalhos com diversos grupos de estudo voltados a agricultura, sobretudo em áreas fitopatológicas, com ênfase em doenças de plantas, sobretudo em oleícolas, com desenvolvimento de pesquisa juntamente a Embrapa com o manejo Stromatinia cepivora. Possui experiência no manejo de doenças epidemiológicas causadas nas cultura de trigo e milho. É parceiro da cachaça Requinte do Emboque, com acompanhamento do processo produtivo do campo a qualidade de bebida. Atualmente sou aluno do mestrado do programa de pós-graduação em Fitopatologia (Capes 7) pela Universidade Federal de Viçosa - Campus Viçosa, e atuo no Laboratório de Manejo Integrado de Doenças (LAMID), sob orientação do professor Franklin Jackson Machado.\n\n\n\n\n\n\nSobre esse site: A proposta desse website é disponibilizar as aulas que foram ministradas na disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia, da Universidade Federal de Viçosa, pelo professor Emerson Del Ponte. Espero que aproveite o conteúdo!!"
  }
]