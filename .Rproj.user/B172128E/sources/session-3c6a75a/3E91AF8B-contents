---
title: "Estatística inferencial: ANOVA e teste de médias"
format: html
editor: visual
message: false
warnig: false
---

Durante a aula 6, utilizando a estatística inferencial. O \$ é utilizado para puxar o dado de uma coluna dentro do conjunto de dados; já o \~ utiliza um fator em função do outro. 

## **Pacotes carregados**

```{r}
library(tidyverse)
library(gsheet)
library(multcomp)
library(multcompView)
```

## **Importando dados**

```{r}
#Importar pacotes 

mg <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137")

```

## Para dois grupos diferentes (independentes)

Para esse conjunto de dados, temos um fator com dois níveis: com e sem magnésio (Mg). Observamos que o magnésio tem um efeito redutor no tamanho da lesão, indicando que a aplicação de Mg está induzindo uma reação de resistência. O tamanho da lesão é maior no tratamento controle. Para publicar este trabalho, é necessário testar a hipótese de que "a suplementação de magnésio reduz o tamanho da doença" (hipótese experimental), enquanto a hipótese nula afirma que as médias não diferem (hipótese estatística). No gráfico, vemos um boxplot simétrico com uma diferença clara entre as medianas, sugerindo a possibilidade de uma diferença significativa. A simetria do boxplot já indica uma possível normalidade dos dados, o que facilita a visualização.

```{r}
#vizualização
mg |> 
  ggplot(aes(trat, comp))+
  geom_boxplot()

#demonstra o efeito da suplementação de magnesio que induz a resistencia, visando testar uma hipotese cientifica é que com a suplementação induz a resistencia 
#a hipotese nula é que o valor das populações são iguais.  
```

Teste T, usado para dois grupos independentes, primeiro existe se existe uma normalidade, dendencia ou independencia e se as variancias são homogeneas. (teste T não pareado), quem inventou o test t? student

Para verificar se há diferença ou não, utilizaremos o teste t, que é um teste simples geralmente usado para comparar dois grupos. Se houver mais de dois grupos, seria necessário fazer comparações par a par. Assumimos a normalidade dos dados e a homogeneidade das variâncias, pois temos um número pequeno de tratamentos. No experimento, 10 plantas receberam um tratamento e 10 plantas receberam outro, o que as torna variáveis independentes.

```{r}
#teste T 

#longo para o largo (ver o formato antes tem que larogo)
mg2 <- mg |> 
  pivot_wider(names_from = trat,
              values_from = comp)

teste1 <- t.test(mg2$Mg2, mg2$control, )

#interpretação: o teste T - ligado ao erro padrão, a probabilidade é pequena pelo fato do p valor ter dado p-value = 2.423e-07 que nesse caso é menor que 0.5 rejeitando a hipotese nula. conclunido que o teste t esta correto. o intervalo de confiança é a diferença verdadeira entre as médias, dado pela ordem de montagem do teste. 

```

#### **Verificação das premissas**

```{r}
#testar a normalidade 
shapiro.test(mg2$control)

#testar a normalidade hipotese nula, dizendo que a distribuição é normal, maior que 0.5 normalidade. 

hist(mg2$control)
#faz-se o histograma para saber se é normal 
```

Histogramas: Uma forma de se avaliar a normalidade visualmente.

A avaliação também pode ser feita utilizando testes estatísticos. Nesse caso, será aplicada uma função nativa do R que é o `shapiro.test`:

```{r}
#testar a normalidade para mg 
shapiro.test(mg2$Mg2)

#demosnta uma distribuição normal acima de 0.5


hist(mg2$Mg2)

#os dados possuem distribuição normal. Os histogramas possuem formato típico de um conjunto de dados normais. Nos Q-Q Plots, é possível notar que os pontos estão próximo a linha de normalidade. E pelos testes de Shapiro Wilk, não se rejeita a hipótese nula (de normalidade), já que valor de P é maior que o nível de significância adotado (⍺ = 5%).
```

#### **Teste de homogeneidade**

Para avaliar a homogeneidade vai se utilizar a função `var.test`:

```{r}
#teste F que compara duas variancias

var.test(mg2$control, mg2$Mg2)

```

Q-Q Plot pode observar a normalidade:

```{r}
qqnorm(mg2$control)
qqline(mg2$control)
```

```{r}
library(report)
report(teste1)
```

## Para dois Grupos dependentes

## **Importando dados**

```{r}
#para dois grupos, vai usar o test t pareado 

#importar o pacote de dados:


escala <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173")

```

Para demonstrar a aplicação do teste t pareado (ou para amostras dependentes), utilizaremos um conjunto de dados contendo os resultados de avaliação de doenças antes e após o uso de uma escala de doenças. O objetivo será determinar se o uso da escala tem algum efeito sobre as avaliações.

```{r}
library(dplyr)
escala2 <- escala |> 
  dplyr::select(assessment, rater, acuracia) |> 
  pivot_wider(names_from = assessment,
              values_from = acuracia)
escala2
```

```{r}
escala |> 
  ggplot(aes(assessment, acuracia))+
  geom_boxplot()

#neste caso sugere falta de normalidade
```

```{r}
shapiro.test(escala2$Unaided)
shapiro.test(escala2$Aided1)


#regeita a hipotese nula e aceita a falta de normalidade pq p-value = 0.007155. 

```

```{r}
var.test(escala2$Unaided, escala2$Aided1)
# se a variancia é homogenea ou não 
```

```{r}
t.test(escala2$Aided1, escala2$Unaided,
       paired = TRUE,
       var.equal = FALSE)

#teste de comparação de dois grupos de media, com 3 ou mais usa-se anova

```

Equivalente ao não parametico do teste t.

```{r}
wilcox.test(escala2$Aided1,
            escala2$Unaided, 
            paired = TRUE) 


#Teste não paramétrico: Utilizado porque o teste de shapiro wilk não deu a normalidade dos dados. Geralmente, os testes paramétricos têm mais poder, mas utilizar o paramétrico ou o não paramétrico está correto nos dois tipos de testes desde que você siga as premissas para a utilização de cada teste.

```

## Para três grupos ou mais

## **Importando dados**

```{r}
micelial <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827")
```

A anova vai testar se existe diferença entre as médias, testando a variabilidade dentro do grupo e entre os grupos. Usou o `geom_jitter` por que tem menos de 10 repetições e é legal visualizar os dados um a um.

```{r}
micelial |> 
  ggplot(aes(especie, tcm))+
  geom_jitter(width = 0.05)

#menos de oito (6 pontos) - geom_jitter


#Com o gráfico a seguir, não é possível observar visualmente se há ou não diferença entre as médias das espécies. A distribuição não é homogênea.Demonstra que variabilidade dentro de cada grupo é grande.
```

Se as médias não diferem, não faz mais sentido continuar o teste de comparação de médias.

```{r}
#anova 


m1 <- lm(tcm ~ especie -1 , data = micelial)

anova(m1)
summary(m1)
  

#segundo o teste da anova não há difrença estatistica entre as especies apenas numerica, todas com uma taxa micelial muito alta. 

```

Para manter o mesmo tema:

```{r}
theme_set(theme_bw())

#manter o mesmo tema 
```

O Emmeans define as médias diretamente. Definindo um teste estatístico para comparação do crescimento.

```{r}
library(emmeans)
medias1 <- emmeans(m1, ~ especie)
medias1

library(multcomp)



library(multcompView)

cld(medias1)
```

```{r}
hist(m1$residuals)
```

#### **Verificação das premissas**

O teste de shapiro executado indica normalidade dos resíduos. P valor = 0,8782. Não rejeita a hipótese.

```{r}
shapiro.test(m1$residuals)
#não rejeita a hipotese p-value = 0.8782.
```

o `bartlett.test` testa se várias amostras possuem variâncias iguais. Esse teste é útil quando você está realizando análises que assumem a homogeneidade das variâncias.

```{r}
bartlett.test(tcm ~ especie, data = micelial)
```

```{r}
library(DHARMa)
plot(simulateResiduals(m1))
```

#### **Verificação das premissas**

```{r}
library(performance)
check_normality(m1)
check_heteroscedasticity(m1)
check_model(m1)
```

Durante a aula 7 do dia 24/04, vamos continuar a aula anterior:

```{r}
inseticida <- InsectSprays

library(tidyverse)

inceticida <- InsectSprays
inceticida |> 
  count(spray)

#anova com um fator ou seis niveis de fator 
```

Exploração do conjunto de dados - variavel numerica discreta

```{r}
inceticida |> 
ggplot(aes(spray, count))+
  geom_boxplot()+
  geom_jitter(width = 0.05)
#observando podemos inferir que as variâncias são heterogêneas. Tratamento com maior variabilidade (F), com menos variabilidade (C) e que possui outlier.


```

Ajusta a nova e trabalha com os residuos da anova e ai parte pa os testes, usando performace e darman. O modelo de ANOVA é ajustado, e trabalhamos com os resíduos da ANOVA, e não com os dados originais, e aí são aplicados os testes.

```{r}
m1 <- lm(count ~ spray, 
         data = inceticida)
m1
```

```{r}
summary(m1)
```

```{r}
anova(m1)
```

```{r}
hist(m1$residuals)
```

shapiro mostra que significativo não é normal, se for significativo é normal.

```{r}
shapiro.test(m1$residuals)

```

Premissa importante: tem maior peso na decisão - homocedasticidade.

```{r}
qqnorm(m1$residuals)
qqline(m1$residuals)
#Quando os pontos acompanham a linha de tendência central, acusa que os dados são normais.

```

o que é mais importante a normalidade ou variancias homogeneas o que é a violação mais problematica?

homocedasticidade(?)

Quando temos dados de contagem normalmente a raiz é uma boa opção.

#### `Bartlett - test`

É uma função utilizada para testar a homogeneidade das variâncias entre diferentes grupos. Ele verifica se várias amostras possuem variâncias iguais.

```{r}
bartlett.test(count ~ spray,
              data = inseticida)
```

#### **Verificação das premissas**

Neste caso não atendeu!

```{r}
check_normality(m1)
```

```{r}
check_heteroscedasticity(m1)
```

```{r}
library(DHARMa)
plot(simulateResiduals(m1))
```

Se não atendeu pode se fazer a transformação de dados:

-   Extrair a raiz quadrada (apropriada pra dados de contagem); Ou usar log.

### **Alternativa 01 - Extração da Raiz quadrada**

```{r}
inseticida <- inseticida |> 
   mutate(count2 = sqrt(count))

inseticida |> 
  ggplot(aes(spray, count2))+
  geom_boxplot()+
  geom_jitter()+
  theme_bw()
  
#normalidade não é um problema aqui, e sim a variância.
```

com a ajuda dos resultados abaixo é possível inferenciar que os problemas de normalidade foram resolvidos.

```{r}
m2 <- lm (count2 ~ spray, data = inseticida)

anova(m2)
summary(m2)

hist(m2$residuals)
shapiro.test(m2$residuals)

qqnorm(m2$residuals)
qqline(m2$residuals)

bartlett.test(count2 ~ spray,
              data = inseticida)

library(performance)
check_normality(m2)
check_heteroscedasticity(m2)


```

#### **Verificação das premissas**

```{r}
check_normality(m2)
```

```{r}
check_heteroscedasticity(m2)
```

```{r}
plot(simulateResiduals(m2))
```

**Alternativas para visualização das comparações de médias**

-   É possível observar que a transformação dos dados resolveu a dispersão das variâncias. Podemos continuar com o teste. O resultado foi não significativo. Podemos seguir com a estimativa das médias. A função `pwpp` (`emmeans`) constrói uma plotagem de valores de probabilidade associados as comparações pareadas das médias marginais estimadas.

    ```{r}
    library(emmeans)
    m2_medias <- emmeans(m2, ~ spray)
    plot(m2_medias)
    library(multcomp)
    cld(m2_medias)
    pwpm(m2_medias)
    pwpp(m2_medias)

    ```

### Alternativa 2 - Teste não paramétrico - Sem transformar

```{r}
library(agricolae)
kruskal.test(count ~ spray, 
             data = inceticida)

#rejeita 
#ipotese nula é que as médias são iguais o que demonstra que rejeita - com 3 grupos ou mais 
```

Rejeita-se a hipótese nula, porque o P é menor que 0,05.

```{r}
m3 <- kruskal(inseticida$count,
        inceticida$spray, 
        group = TRUE)
m3

#da a media dos tratamentos e um ranking para fazer a estatistica, calculando os agrupamentos. 3 grupos ranqueados. o não parametrico deu o mesmo resultado que o modelo transformado. podendo partir para a alternativa 3 assumindo que a distribuição é de acordo com os dados podendo ser poason (modelo linear generalizado - mais moderno)
```

### Alternativa 3 - GLMs

```{r}
m4 <- glm(count ~ spray,
          family = poisson, data = inseticida)
summary(m4)
anova(m4)
library(car)
Anova(m4)
```

```{r}
plot(simulateResiduals(m4))
```

```{r}
m4_medias <- emmeans(m4, ~spray,
                     type = "response")
cld(m4_medias)
```

valor original - observação resposta original

anova - testo pressupostos

alternativa 1 - trasformação

busca normalização

a2- não parametrico

a3- GLMs

faz tudo isso para cada variavel

-   Transformação BOX-COX

    ```{r}
    library(MASS)
    b <- boxcox(lm(inceticida$count+0.1 ~1))
    lambda <- b$x[which.max(b$y)]
    lambda
    inceticida$count3 <- (inceticida$count ^  lambda - 1) / lambda
    inceticida$count3

    #mandeira de tranformar 
    ```

uso do novo conjunto uma anova para dois fatores.

#anova Fatorial

```{r}
li <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672")

```

```{r}
li |> 
  ggplot(aes(factor(dose), severity, color = factor(dose)))+
  geom_jitter(whidth = 0.1)+
 facet_wrap(~treat)


```

#modelo fatorial (two-way anova)

```{r}
mf <- lm(severity ~ treat * dose, 
         data = li)
mf
anova(mf)

#demostra que a interassão é significativa, as doses estão diretamente ligadas aos tratamentos. 
```

testar as primicias

```{r}
plot(simulateResiduals(mf))

#não teve problema 

```

Compraçaõ de medias, dentro das linhas e dentro das colunas

```{r}
mf_medias <- (mf ~ treat | dose)
#cld(mf_medias)

#comparou coluna 
```

```{r}
# comprar as linhas 
mf_medias <- emmeans(mf, ~ dose | treat)
cld (mf_medias)
```
